---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.5.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
import locale
import re
import requests
import unicodedata
from collections import Counter, defaultdict
from urllib.parse import urljoin
from tqdm import tqdm

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
from matplotlib import font_manager as fm


import pymorphy2 as pm

plt.rcParams.update({'figure.figsize': [12, 8]})
locale.setlocale(locale.LC_TIME, 'ru_RU.UTF-8');
```

```{python}
font_dirs = ['./fonts/', ]
font_files = fm.findSystemFonts(fontpaths=font_dirs)
font_list = fm.createFontList(font_files)
fm.fontManager.ttflist.extend(font_list)

plt.rcParams['font.family'] = 'Roboto'
```

```{python}
class KeyDict(defaultdict):
    def __missing__(self, key):
        return key
```

```{python}
morpher = pm.MorphAnalyzer()

raw = pd.read_json('vacancies.json', lines=True)
raw = raw.applymap(lambda s: unicodedata.normalize('NFKD', s) if type(s)==str else s)
raw[['date', 'place']] = raw['timestamp'].str.extract('(\d+ \w+ \d+) в (.+)')
raw = raw.drop('timestamp', axis=1)
raw['date'] = pd.to_datetime(raw['date'], format="%d %B %Y")
raw['place'] = [morpher.parse(s)[0].normal_form.title() for s in raw['place']]
```

## Основные тэги

```{python}
tags = [tag for tag_list in raw['tags'] for tag in tag_list]
tags_counter = Counter(tags)
```

```{python}
plot_data = tags_counter.most_common(20)
plot_data = [[x[0] for x in plot_data], 
             [x[1] for x in plot_data]]

plt.barh(y=plot_data[0], width=plot_data[1], color='#87A96B')
plt.yticks(fontsize=14)
plt.xticks(np.arange(0, np.max(plot_data[1])), fontsize=14)
plt.xlabel("Количество упоминаний тэга", fontsize=14)
plt.title("20 самых частых тэгов вакансий", fontsize=18, weight='bold')
plt.gca().spines['right'].set_color('none')
plt.gca().spines['top'].set_color('none')
plt.gca().spines['left'].set_color('none')
plt.gca().invert_yaxis()
plt.show()
```

## Зарплата
Зарплата может быть в разной валюте. В данный момент, этот отчёт умеет обрабатывать следующие валюты: KZT, USD, EUR, рубли, белорусские рубли. В ячейке ниже будут указаны валюты, которые не обработаны.

```{python}
currencies = ['бел', 'USD', 'EUR', 'KZT', 'руб']
pattern = '|'.join(currencies)
unknown_currencies = raw.loc[~raw['salary'].str.contains(pattern),'salary']
unknown_currencies.value_counts()
```

Как видно, в отчёте останутся необработанными только те вакансии, где зарплата не указана.

```{python}
cur_to_code = KeyDict()
cur_to_code.update({'бел': 'BYN', 'руб': 'RUB'})
```

```{python}
API_KEY = 'f57760a8c9133fde8b40'
CUR_CODES = ['BYN', 'USD', 'EUR', 'KZT']
URL = 'https://free.currconv.com/api/v7/convert'
queries = ['_'.join((x, 'RUB')) for x in CUR_CODES]
params = {'compact': 'ultra',
          'apiKey': API_KEY}

cur_dict = {'RUB': 1}
for query in queries:
    params.update({'q': query})
    resp = requests.get(URL, params=params)
    cur_dict.update(resp.json())
cur_dict = {k[:3]: v for k,v in cur_dict.items()}
```

```{python}
cur_string='|'.join(currencies)
pattern = '(от|до)((\d+)до(\d+)|\d+)({})'.format(cur_string)

counts = raw['salary'].copy()
counts = counts.str.replace(' ', '')
counts = counts.str.extract(pattern).dropna(how='all')
counts[1] = [x if x.isdigit() else None for x in counts[1]]
counts[4] = counts[4].map(cur_to_code)
counts[4] = counts[4].map(cur_dict)
counts.iloc[:, 1:4] = counts.iloc[:,1:4].apply(pd.to_numeric)
counts[2] = (counts[2] + counts[3]) / 2
counts[1] = np.where(counts[0] == 'до', counts[1]/2, counts[1])
counts[1] = counts[1].combine_first(counts[2])
counts[1] = counts[1]*counts[4]
counts = counts.drop([0,2,3,4], axis=1)
counts = counts.rename(columns={1:'salary'})
```

```{python}
max_salary = max(counts['salary'])
bins = np.arange(0, max_salary, 10000)

plt.clf()
plt.hist(counts['salary'], bins=bins, color='#87A96B')
plt.xticks(np.arange(0, max_salary, 10000), fontsize=14)
plt.gca().yaxis.set_major_locator(ticker.MaxNLocator(integer=True))
plt.xlabel("Зарплата, руб.")
plt.ylabel("Количество вакансий")
plt.title("Гистограмма зарплат")
plt.show()
```

Добавим столбец обработанных зарплат в таблицу для дальнейшей обработки

```{python}
processed = raw.copy()
processed['salary'] = counts
```

## Удалёнка


Посмотрим, какая доля вакансий содержит предложение об удалённом трудоустройстве.

```{python}
remote_df = processed.loc[processed['description'].str.contains('удален|remote'), :]
office_df = processed.loc[~processed['description'].str.contains('удален|remote'), :]
remote_share = len(remote_df) / len(processed) * 100
print("Удалённую работу предлагают в {:.2f}% вакансий".format(remote_share))
```

Есть ли разница между зарплатами на удалёнке и на полном рабочем дне?

```{python}
missed_remote = remote_df['salary'].isna().sum() / len(remote_df) * 100
missed_office = office_df['salary'].isna().sum() / len(office_df) * 100
print("Доля вакансий без указания зарплат среди групп:")
print("Предложения удалённой работы: {:.2f}%".format(missed_remote))
print("Предложения трудоустройства в офисе: {:.2f}%".format(missed_office))
```

```{python}
mean_remote = remote_df['salary'].mean()
mean_office = office_df['salary'].mean()
median_remote = remote_df['salary'].median()
median_office = office_df['salary'].median()

plt.subplot(121)
plt.bar(('Удалёнка', 'Офис'), height=(median_remote, median_office))
plt.ylabel('Зарплата, руб.')
plt.title('Медианная зарплата')
plt.subplot(122)
plt.bar(('Удалёнка', 'Офис'), height=(mean_remote, mean_office))
plt.title('Средняя зарплата')
plt.suptitle('Сравнение доходов на удалёнке и в офисе')
plt.show()
```

## География вакансий

```{python}
cities = processed['place'].value_counts()[:15]

plt.barh(cities.index, cities)
plt.gca().invert_yaxis()
plt.xlabel('Количество вакансий')
plt.title('Распределение вакансий по городам')
plt.show()
```

## Анализ ключевых слов

```{python}
import nltk
```

```{python}
stopwords_rus = nltk.corpus.stopwords.words('russian')
stopwords_eng = nltk.corpus.stopwords.words('english')

tokens = tqdm([nltk.word_tokenize(x, language='russian') for x in processed['description']])
tokens = tqdm([token for tokens_list in tokens for token in tokens_list])
tokens = tqdm([token.lower() for token in tokens if token.isalpha()])
tokens = tqdm([morpher.parse(token)[0].normal_form for token in tokens])
tokens = tqdm([token for token in tokens if token not in stopwords_rus])
tokens = tqdm([token for token in tokens if token not in stopwords_eng])
```

```{python}
idx = nltk.text.ContextIndex(tokens)
fdist = nltk.FreqDist(tokens)
```

```{python}
keywords = [x[0].lower() for x in tags_counter.most_common(20)]

similar = []
for word in tqdm(keywords):
    similar.append(idx.similar_words(word, n=100))
similar = [word for wlist in similar for word in wlist]
similar = [word for word in similar if re.match('[a-z]+', word)]
similar = list(set(similar))
freqs = list(map(fdist.get, similar))
```

```{python}
top_words_df = pd.DataFrame(zip(similar, freqs), columns=['word', 'count'])
top_words_df = top_words_df.sort_values('count', ascending=False)
top_words_df = top_words_df.reset_index(drop=True)[:40]
```

```{python}
plt.barh(top_words_df['word'], top_words_df['count'])
plt.gca().invert_yaxis()
plt.title('Ключевые слова вакансий (англ.)')
plt.xlabel('Количество упоминаний')
plt.show()
```

## Даты размещения вакансий

```{python}
dates = processed.groupby('date')['vac_id'].count().rename('count')
```

```{python}
plt.figure(figsize=(12,8))
plt.plot(dates.index, dates, marker='o')
plt.grid(ls='--')
plt.gca().tick_params('x', labelrotation=45)
plt.gca().spines['top'].set_color('none')
plt.gca().spines['right'].set_color('none')
plt.xlabel('Дата публикации')
plt.ylabel('Количество опубликованных вакансий')
plt.title('Распределение вакансий по дате публикации')
plt.show()
```

```{python}

```
